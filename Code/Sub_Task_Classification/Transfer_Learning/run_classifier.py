# -*- coding: utf-8 -*-
"""CIS522_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o_4Jc5ni_Nlk-7qBztDOY50Vr3ouoe7h
"""

#%matplotlib inline
import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.utils.data
import torchvision.datasets as dset
import torchvision.utils as vutils
from shutil import copyfile
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from torchvision.transforms import ToTensor
import torchvision
import numpy as np
import PIL
from sklearn import metrics
from tqdm import notebook

from classes import *
from utils import *
from config import config

# Set random seed for reproducibility
manualSeed = 999
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

# partition the whole dataset into train and val datasets

DATA_PATH = './train/'
TRAIN_PATH = './train/'
VAL_PATH = './val/'
num_each_class = 800
# num of validation imgs per class
n = 80

num_classes = len(os.listdir(DATA_PATH))
print('Total number of classes: %d' % (num_classes))

labels = os.listdir(DATA_PATH)
print(labels)

# for filename in os.listdir(DATA_PATH):
#     if os.path.isdir(DATA_PATH+filename):
#         folder_path = os.path.join(DATA_PATH, filename)
#         train_folder_path = os.path.join(TRAIN_PATH, filename)
#         val_folder_path = os.path.join(VAL_PATH, filename)
#         if not os.path.isdir(train_folder_path):
#             os.mkdir(train_folder_path)
#         if not os.path.isdir(val_folder_path):
#             os.mkdir(val_folder_path)

#         all_data = os.listdir(folder_path)

#         random.shuffle(all_data)
#         train_data = all_data[n:]
#         val_data = all_data[:n]


#         for img in train_data:
#             img_path = os.path.join(folder_path, img)
#             copyfile(img_path, os.path.join(train_folder_path, img))

#         for img in val_data:
#             img_path = os.path.join(folder_path, img)
#             copyfile(img_path, os.path.join(val_folder_path, img))



device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

batch_size = config.batch_size
img_size = config.img_size

# train dataloader
train_transforms = transforms.Compose([
        transforms.Resize(128),
        # transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
training = torchvision.datasets.ImageFolder(TRAIN_PATH, transform = train_transforms)
train_dataloader = torch.utils.data.DataLoader(training,batch_size=batch_size,shuffle=True,drop_last=True)

# validation dataloader
val_transforms = transforms.Compose([
        #transforms.Resize(256),
        transforms.Resize(128),
        #transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
validation = torchvision.datasets.ImageFolder(VAL_PATH, transform = val_transforms)
val_dataloader = torch.utils.data.DataLoader(validation,batch_size=batch_size,shuffle=True,drop_last=True)

print('Using device:', device)

# # train Logistic regression model
# input_size = config.input_size
# output_size = config.output_size
# epochs = config.num_epochs
# lr = config.learning_rate

# # model = LogisticRegression(input_size, output_size)
# model = SimpleNetwork(input_size, output_size)
# loss_fcn = torch.nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=lr)
# exp_lr_scheduler = None

# model.to(device)

# labels = []
# display_labels = []

# for k,v in training.class_to_idx.items():
#     labels.append(v)
#     display_labels.append(k)

# train Transfer Learning Model
input_size = config.input_size
output_size = config.output_size
epochs = config.num_epochs
lr = config.learning_rate

model = models.resnet18(pretrained=True)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, config.output_size)
model.to(device)


loss_fcn = nn.CrossEntropyLoss()
# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.2)


train_model(train_dataloader, model, optimizer, exp_lr_scheduler, loss_fcn, epochs, evaluate=True,
    val_dataloader=val_dataloader, write_logs=True)

# eval_model(train_dataloader, model, loss_fcn)

# train neural net model
# input_size = 3*256*256
# output_size = 50
# epochs = 5
# lr = 1e-3

# model = SimpleNetwork(input_size, output_size)
# loss_fcn = torch.nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=lr)


# train_model(train_dataloader, model, optimizer, loss_fcn, epochs, evaluate=True)
